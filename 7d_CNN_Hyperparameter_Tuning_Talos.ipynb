{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancLis/Multivariate-Time-Series-Forecasting/blob/main/7d_CNN_Hyperparameter_Tuning_Talos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C5D4-G1XC32"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzeMYy1p4Lp9"
      },
      "source": [
        "In this notebook is shown the code used for some experiments of Hyperparameter tuning made using the library Talos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3_7phLIJtws"
      },
      "outputs": [],
      "source": [
        "!pip install talos\n",
        "!pip install joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xhf0TVeCAITf"
      },
      "outputs": [],
      "source": [
        "# Seed value\n",
        "# Apparently you may use different seed values at each stage\n",
        "seed_value = 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "# The below is necessary for starting Numpy generated random numbers\n",
        "# in a well-defined initial state.\n",
        "np.random.seed(123)\n",
        "\n",
        "# The below is necessary for starting core Python generated random numbers\n",
        "# in a well-defined state.\n",
        "python_random.seed(123)\n",
        "\n",
        "# The below set_seed() will make random number generation\n",
        "# in the TensorFlow backend have a well-defined initial state.\n",
        "# For further details, see:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import talos as ta\n",
        "from numpy import zeros, newaxis\n",
        "from matplotlib import pyplot as plt\n",
        "from joblib import dump, load\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler, PowerTransformer, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, max_error, mean_absolute_error\n",
        "from tensorflow.keras.optimizers import Adam, Nadam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import Sequential, layers, callbacks\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Dropout, GRU, Bidirectional, SimpleRNN, Conv1D, MaxPooling1D, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBvYW-71LYh7"
      },
      "source": [
        "Load and read preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkcaZZKFd5QA"
      },
      "outputs": [],
      "source": [
        "with open('Preprocessed_data_PG.npy', 'rb') as f:\n",
        "    X_train = np.load(f)\n",
        "    y_train = np.load(f)\n",
        "    X_valid = np.load(f)\n",
        "    y_valid = np.load(f)\n",
        "    X_test = np.load(f)\n",
        "    y_test = np.load(f)\n",
        "\n",
        "print('All shapes are: (batch, time, features)')\n",
        "print('X_train.shape:', X_train.shape, 'y_train.shape:', y_train.shape)\n",
        "print('X_valid.shape:', X_valid.shape, 'y_valid.shape:', y_valid.shape)\n",
        "print('X_test.shape:', X_test.shape, 'y_test.shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es-3SjBjTGax"
      },
      "source": [
        "Load scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDFUkU63TGsE"
      },
      "outputs": [],
      "source": [
        "scaler = load('PowerTransformer_Close_PG.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByOexPRLbboE"
      },
      "source": [
        "It was verified through these lines of code that the two scales were equal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eY-by2p2bm0v"
      },
      "outputs": [],
      "source": [
        "# Those attributes are specific of MinMaxScaler. For other scalers they might change\n",
        "# if (imported_scaler.scale_ == scaler.scale_).all() and (imported_scaler.data_max_ == scaler.data_max_).all() \\\n",
        "        # and (imported_scale.data_min_ == scaler.data_min_).all() and (imported_scale.data_range_ == scaler.data_range_).all():\n",
        "   # print(\"Scalers are same\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY4y8A4zc_Ix"
      },
      "source": [
        "It is necessary to import the shoe ladder then subsequently the new observations that the algorithm will predict in the future which will then be reused for the next prison prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6k_ZsXzICT8"
      },
      "outputs": [],
      "source": [
        "# from talos.utils import hidden_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx941nYNdFkl"
      },
      "source": [
        "The Hidden layers function has been imported from the Talos library but has been modified according to the needs of the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwSkU0oqhJwz"
      },
      "outputs": [],
      "source": [
        "def network_shape_customized(params, last_neuron, network_type):\n",
        "    '''Provides the ability to include network shape in experiments. If params\n",
        "    dictionary for the round contains float value for params['shapes'] then\n",
        "    a linear contraction towards the last_neuron value. The higher the value,\n",
        "    the fewer layers it takes to reach lesser than last_neuron.\n",
        "    Supports three inbuilt shapes 'brick', 'funnel', and 'triangle'.\n",
        "    params : dict\n",
        "         Scan() params for a single roundself.\n",
        "    last_neuron : int\n",
        "         Number of neurons on the output layer in the Keras model.\n",
        "    '''\n",
        "    import numpy as np\n",
        "    from talos.utils.exceptions import TalosParamsError\n",
        "\n",
        "    layers = params['hidden_layers']\n",
        "    shape = params['shapes']\n",
        "    # network_type == 0 --> SimpleRNN\n",
        "    # network_type == 1 --> GRU\n",
        "    # network_type == 2 --> LSTM\n",
        "    # network_type == 3 --> CONV1D\n",
        "    if network_type == 3:\n",
        "        first_neuron = params['first_filter']\n",
        "    else:\n",
        "        first_neuron = params['first_neuron']\n",
        "\n",
        "    out = []\n",
        "    n = first_neuron\n",
        "\n",
        "    # the case where hidden_layers is zero\n",
        "    if layers == 0:\n",
        "        return [0]\n",
        "\n",
        "    # the cases where an angle is applied\n",
        "    if isinstance(shape, float):\n",
        "\n",
        "        for i in range(layers):\n",
        "\n",
        "            n *= 1 - shape\n",
        "\n",
        "            if n > last_neuron:\n",
        "                out.append(int(n))\n",
        "            else:\n",
        "                out.append(last_neuron)\n",
        "\n",
        "    # the case where a rectantular shape is used\n",
        "    elif shape == 'brick':\n",
        "        out = [first_neuron] * layers\n",
        "\n",
        "    elif shape == 'funnel':\n",
        "        for i in range(layers + 1):\n",
        "            n -= int((first_neuron - last_neuron) / layers)\n",
        "            out.append(n)\n",
        "        out.pop(-1)\n",
        "\n",
        "    elif shape == 'triangle':\n",
        "        out = np.linspace(first_neuron,\n",
        "                          last_neuron,\n",
        "                          layers + 2,\n",
        "                          dtype=int).tolist()\n",
        "\n",
        "        out.pop(0)\n",
        "        out.pop(-1)\n",
        "        out.reverse()\n",
        "\n",
        "    else:\n",
        "        message = \"'shapes' must be float or in ['funnel', 'brick', 'triangle']\"\n",
        "        raise TalosParamsError(message)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def hidden_layers_customized(model, params, last_neuron, network_type):\n",
        "    '''HIDDEN LAYER Generator\n",
        "\n",
        "    NOTE: 'shapes', 'first_neuron', 'dropout', and 'hidden_layers' need\n",
        "    to be present in the params dictionary.\n",
        "\n",
        "    Hidden layer generation for the cases where number\n",
        "    of layers is used as a variable in the optimization process.\n",
        "    Handles things in a way where any number of layers can be tried\n",
        "    with matching hyperparameters.'''\n",
        "\n",
        "    # check for the params that are required for hidden_layers\n",
        "\n",
        "    from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, SimpleRNN, GRU, LSTM\n",
        "    # from .network_shape import network_shape\n",
        "    from talos.utils.exceptions import TalosParamsError\n",
        "\n",
        "    if network_type != 3:\n",
        "        required = ['shapes', 'first_neuron', 'hidden_layers',]\n",
        "    else:\n",
        "        required = ['shapes', 'first_filter', 'hidden_layers', 'kernel_size',]\n",
        "\n",
        "    for param in required:\n",
        "        if param not in params:\n",
        "            message = \"hidden_layers requires '\" + param + \"' in params\"\n",
        "            raise TalosParamsError(message)\n",
        "\n",
        "    layer_neurons = network_shape_customized(params, last_neuron, network_type)\n",
        "    # network_type == 0 --> SimpleRNN\n",
        "    # network_type == 1 --> LSTM\n",
        "    # network_type == 2 --> GRU\n",
        "    # network_type == 3 --> CONV1D\n",
        "    from keras.regularizers import l2\n",
        "    if network_type == 0:\n",
        "        for i in range(params['hidden_layers']):\n",
        "            if params['hidden_layers'] == 0:\n",
        "                model.add(SimpleRNN(layer_neurons[i], return_sequences=False,\n",
        "                                    kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                    activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "            else:\n",
        "                if i == params['hidden_layers'] - 1:\n",
        "                    model.add(SimpleRNN(layer_neurons[i], return_sequences=False,\n",
        "                                        kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                        activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "                else:\n",
        "                    model.add(SimpleRNN(layer_neurons[i], return_sequences=True,\n",
        "                                        kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                        activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "    elif network_type == 1:\n",
        "        for i in range(params['hidden_layers']):\n",
        "            if params['hidden_layers'] == 0:\n",
        "                model.add(LSTM(layer_neurons[i], return_sequences=False,\n",
        "                               kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                               activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "            else:\n",
        "                if i == params['hidden_layers'] - 1:\n",
        "                    model.add(LSTM(layer_neurons[i], return_sequences=False,\n",
        "                                   kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                   activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "                else:\n",
        "                    model.add(LSTM(layer_neurons[i], return_sequences=True, \n",
        "                                   kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                   activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "    elif network_type == 2:\n",
        "        for i in range(params['hidden_layers']):\n",
        "            if params['hidden_layers'] == 0:\n",
        "                model.add(GRU(layer_neurons[i], return_sequences=False,\n",
        "                              kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                              activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "            else:\n",
        "                if i == params['hidden_layers'] - 1:\n",
        "                    model.add(GRU(layer_neurons[i], return_sequences=False,\n",
        "                                  kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                   activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "                else:\n",
        "                    model.add(GRU(layer_neurons[i], return_sequences=True,\n",
        "                                  kernel_regularizer=keras.regularizers.l2(0.01),\n",
        "                                   activity_regularizer=keras.regularizers.l2(0.1),))\n",
        "\n",
        "    elif network_type == 3:\n",
        "        for i in range(params['hidden_layers']):\n",
        "            model.add(Conv1D(layer_neurons[i],\n",
        "                             kernel_size=params.get('kernel_size'),\n",
        "                             padding='same', activation='relu'))\n",
        "            model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "            model.add(Dropout(0))\n",
        "    else:\n",
        "        message = \"Model not supported\"\n",
        "        raise TalosParamsError(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWN6w5LzElbE"
      },
      "source": [
        "#### Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RBbm--LElbF"
      },
      "outputs": [],
      "source": [
        "def cnn1d_fn(x_train, y_train, x_val, y_val, params):\n",
        "    # Step 1: reset the tensorflow backend session.\n",
        "    tf.keras.backend.clear_session()\n",
        "    # Step 2: Define the model with variable hyperparameters.\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train.shape[1], X_train.shape[2])))\n",
        "    hidden_layers_customized(model, params, y_train.shape[1], 3)\n",
        "    model.add(Dropout(0))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(y_train.shape[1]))\n",
        "    model.add(Activation('linear'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='mse',\n",
        "        # metrics=['mse']\n",
        "    )\n",
        "\n",
        "    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=params['epochs'],\n",
        "        batch_size=params['batch_size'],\n",
        "        verbose=0,\n",
        "        validation_data=[x_val, y_val],\n",
        "        callbacks=[stop_early]\n",
        "    )\n",
        "    return history, model\n",
        "\n",
        "\n",
        "para = {\n",
        "    'batch_size': [50, 60], \n",
        "    'epochs': [70, 100],  # 100, 200\n",
        "    'shapes': ['brick', 'triangle',],               # <<< required\n",
        "    'hidden_layers': [2, 3, 4],  # 2, 3         # <<< required\n",
        "    # 'dropout': [0],  # 0.25                        # <<< required\n",
        "    'first_filter': [96, 64, 32],           # <<< required\n",
        "    'kernel_size': [2, 3, 4],               # <<< required\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Starting of Grid search\n",
        "# Choose of model to tune\n",
        "scan_results = ta.Scan(x=X_train,\n",
        "                 y=y_train,\n",
        "                 params=para,\n",
        "                 model=cnn1d_fn,\n",
        "                 experiment_name='Hyperparameter_Tuning',\n",
        "                 x_val=X_valid,\n",
        "                 y_val=y_valid,\n",
        "                 # performance_target=['val_loss', 0.54, True],\n",
        "                 disable_progress_bar=False, \n",
        "                 print_params=True)"
      ],
      "metadata": {
        "id": "sUnphFCHI9X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff2aCAAh-4DV"
      },
      "source": [
        "## 4. Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "is68QDDBmKyu"
      },
      "outputs": [],
      "source": [
        "r = ta.Reporting('/content/Hyperparameter_Tuning/041822112127.csv')\n",
        "\n",
        "# returns the results dataframe\n",
        "r.data.sort_values(by=['val_loss'], ascending=True).iloc[:10, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up2TmQknXtyj"
      },
      "outputs": [],
      "source": [
        "# get correlation for hyperparameters against a metric\n",
        "r.correlate('val_loss', ['loss', 'val_loss', 'round_epochs', 'batch_size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDNJLD9aZY5K"
      },
      "outputs": [],
      "source": [
        "# get a correlation plot for hyperparameters against a metric \n",
        "r.plot_corr('val_loss', ['loss', 'val_loss', 'round_epochs', 'batch_size'])\n",
        "# plt.savefig('curve.png', dpi=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yA_uVZm1OWsw"
      },
      "outputs": [],
      "source": [
        "# Get the best model index with highest 'val_loss' \n",
        "model_id = r.data['val_loss'].astype('float').argmin() - 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get models index from data \n",
        "# model_id = r.data['val_loss'].astype('float').index[26]"
      ],
      "metadata": {
        "id": "1MiiSFNWMCel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id"
      ],
      "metadata": {
        "id": "MXdDMSEHM0xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "negYo6SL6Kxo"
      },
      "source": [
        "* It is possible to retrieve the loss curve of the best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnQqQcHtU5hR"
      },
      "outputs": [],
      "source": [
        "model_history = scan_results.round_history[model_id]\n",
        "\n",
        "# LOSS CURVE\n",
        "# Plot train loss and validation loss\n",
        "def plot_loss(history):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(history['loss'])\n",
        "    plt.plot(history['val_loss'])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
        "    # plt.savefig('Loss curve.png', dpi=1200)\n",
        "    # plt.show()\n",
        "\n",
        "plot_loss(model_history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history['loss'][-1]"
      ],
      "metadata": {
        "id": "3hyJcYB3LObs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_history['val_loss'][-1]"
      ],
      "metadata": {
        "id": "TPPTEFwVLZ4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tm5QhzROrMs"
      },
      "outputs": [],
      "source": [
        "def save_best_model(scan_results, model_id, model_name):\n",
        "    # Clear any previous TensorFlow session.\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "\n",
        "    # Load the model parameters from the scanner.\n",
        "    model = tf.keras.models.model_from_json(scan_results.saved_models[model_id])\n",
        "    model.set_weights(scan_results.saved_weights[model_id])\n",
        "    model.summary()\n",
        "    # model.save('./best_model_' + model_name)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = save_best_model(scan_results, model_id, 'cnn1d')\n",
        "\n",
        "\n",
        "# Code to load that model\n",
        "# my_tf_saved_model = tf.keras.models.load_model('./saved_models/my_tf_model')\n",
        "# my_tf_saved_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdoZ_A18HjEH"
      },
      "outputs": [],
      "source": [
        "def plot_model_summary(model, model_name):\n",
        "    plot_model(model, to_file='model_summary_' + model_name + '.png', show_shapes=True)\n",
        "\n",
        "# Change function according to the model tuned\n",
        "plot_model_summary(model, 'cnn1d')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "def prediction(model):\n",
        "    prediction = model.predict(X_test)\n",
        "    return prediction\n",
        "\n",
        "\n",
        "prediction_cnn1d = prediction(model)"
      ],
      "metadata": {
        "id": "a8MEbPr1ZuNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_cnn1d[:, :] = scaler.inverse_transform(prediction_cnn1d[:, :])\n",
        "y_train[:, :] = scaler.inverse_transform(y_train[:, :])\n",
        "y_test[:, :] = scaler.inverse_transform(y_test[:, :])\n"
      ],
      "metadata": {
        "id": "bc-DWLMcEeS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_cnn1d"
      ],
      "metadata": {
        "id": "JrUPVArdCJKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "PDb_xnkuAT4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_future(prediction, model_name, y_test):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    range_future = len(prediction)\n",
        "    plt.plot(np.arange(range_future), np.array(y_test), label='True Future')\n",
        "    plt.plot(np.arange(range_future), np.array(prediction), label='Prediction')\n",
        "    plt.title('True future vs prediction for ' + model_name)\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlabel('Time (day)')\n",
        "    plt.ylabel('Stock Price (â‚¬)')\n",
        "    # plt.savefig('Prediction_Evaluation_plot_' + model_name + '.png', dpi=1200)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_future(prediction_cnn1d, 'cnn1d', y_test)"
      ],
      "metadata": {
        "id": "YzHxl33BaBQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to calculate MAE and RSME\n",
        "step_ahead=1\n",
        "\n",
        "# Define a function to calculate MAE and RSME\n",
        "def evaluate_prediction(predicted, actual, model_name):\n",
        "    if step_ahead == 1:\n",
        "        rsme = np.sqrt((mean_squared_error(predicted, actual)))\n",
        "        mae = mean_absolute_error(actual, predicted)\n",
        "        r2 = r2_score(actual, predicted)\n",
        "        max_err = max_error(actual, predicted)\n",
        "        print(model_name + ' performance:')\n",
        "        print('R^2: {:.4f} %'.format(r2 * 100))\n",
        "        print('Mean Absolute Error: {:.4f}'.format(mae))\n",
        "        print('Root Mean Square Error: {:.4f}'.format(rsme))\n",
        "        print('Max_error: {:.4f}'.format(max_err))\n",
        "        print('')\n",
        "        return\n",
        "    else:\n",
        "        titles = [\"RMSE\", \"MAE\", \"R^2\"]\n",
        "        # calculate an RMSE score for each day\n",
        "        # calculate mse\n",
        "        rmse = np.sqrt(mean_squared_error(predicted, actual, multioutput='raw_values'))\n",
        "        mae = mean_absolute_error(predicted, actual, multioutput='raw_values')\n",
        "        r2 = r2_score(predicted, actual, multioutput='raw_values')\n",
        "        df_scores = pd.DataFrame(list(zip(rmse, mae, r2)), columns=[f'{x}' for x in titles])\n",
        "        df_scores.index += 1\n",
        "\n",
        "        colors = plt.rcParams[\"axes.prop_cycle\"]()\n",
        "        a = 1  # number of rows\n",
        "        b = 3  # number of columns\n",
        "        c = 1  # initialize plot counter\n",
        "        fig = plt.figure(figsize=(15, 6))\n",
        "        for i in titles:\n",
        "            plt.subplot(a, b, c)\n",
        "            plt.title(f'{i}')\n",
        "            next_colour = next(colors)[\"color\"]\n",
        "            df_scores[f'{i}'].plot(marker='o', color=next_colour)\n",
        "            plt.xticks((range(0, df_scores.shape[0] + 1)))\n",
        "            plt.legend(loc='upper left')\n",
        "            plt.xlabel('Forecast Range (Day)')\n",
        "            plt.ylabel(f'{i}')\n",
        "            c = c + 1\n",
        "\n",
        "        plt.subplots_adjust(.5)\n",
        "        fig.suptitle(\"Evaluation of performances' trend in the multi step forecasted range\", fontsize=16, y=1)\n",
        "        plt.tight_layout()\n",
        "        # plt.savefig('EvaluationMultiplePrediction_PG.png', dpi=1200)\n",
        "        plt.show()\n",
        "\n",
        "        # calculate overall RMSE\n",
        "        overall_rmse = np.sqrt(mean_squared_error(predicted, actual, multioutput='uniform_average'))\n",
        "        overall_mae = mean_absolute_error(predicted, actual, multioutput='uniform_average')\n",
        "        overall_r2 = r2_score(predicted, actual, multioutput='uniform_average')\n",
        "        print(model_name + ' performance:')\n",
        "        print('R^2: {:.4f} %'.format(overall_r2 * 100))\n",
        "        print('Mean Absolute Error: {:.4f}'.format(overall_mae))\n",
        "        print('Root Mean Square Error: {:.4f}'.format(overall_rmse))\n",
        "        print('')\n",
        "        return\n",
        "\n",
        "\n",
        "evaluate_prediction(prediction_cnn_1d, y_test, 'cnn1d')"
      ],
      "metadata": {
        "id": "dYY0YItYaHjm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "7d_CNN_Hyperparameter_Tuning_Talos.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNij/fSfeTYXIXlLcQjdm+l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}